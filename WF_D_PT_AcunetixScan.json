{
  "name": "WF_D_PT_AcunetixScan",
  "nodes": [
    {
      "parameters": {},
      "id": "d-trigger",
      "name": "Trigger",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1,
      "position": [
        -1180,
        160
      ]
    },
    {
      "parameters": {
        "authentication": "headerAuth",
        "url": "={{ ($env.DOJO_BASE_URL || 'http://localhost:8080/api/v2').replace(/\\/+$/,'') + '/products/?tags=targets:ready&limit=200&offset=0' }}",
        "options": {}
      },
      "id": "d-products",
      "name": "Get PT Targets/Products",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        -980,
        160
      ],
      "credentials": {
        "httpHeaderAuth": {
          "id": "mGl4PbJkKfeJbTg8",
          "name": "Header Auth account"
        }
      }
    },
    {
      "parameters": {
        "language": "python",
        "pythonCode": "return [{\"json\": {\"pool_probe\": \"started\"}}]"
      },
      "id": "d-acu-scans",
      "name": "Get Active Acunetix Scans",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -760,
        160
      ]
    },
    {
      "parameters": {
        "language": "python",
        "pythonCode": "import os\nimport json\nimport urllib.request\nimport urllib.error\nimport hashlib\nimport urllib.parse\n\nMAPPING_FILE = (os.environ.get('ACUNETIX_TARGET_MAPPING_FILE') or '/tmp/acunetix_dojo_target_mapping.json').strip()\nPT_NODE_MAPPING_FILE = (os.environ.get('ACUNETIX_PT_NODE_MAPPING_FILE') or '/tmp/acunetix_pt_node_mapping.json').strip()\n\nACTIVE_STATUSES = {'processing', 'scheduled', 'queued', 'starting'}\n\n\ndef parse_positive_int(value, default):\n    try:\n        parsed = int(value)\n        if parsed > 0:\n            return parsed\n    except Exception:\n        pass\n    return default\n\n\ndef parse_bool(value, default=False):\n    if value is None:\n        return default\n    if isinstance(value, bool):\n        return value\n    raw = str(value).strip().lower()\n    if raw in {'1', 'true', 'yes', 'y', 'on'}:\n        return True\n    if raw in {'0', 'false', 'no', 'n', 'off'}:\n        return False\n    return default\n\n\ndef normalize_policy(value):\n    raw = str(value or '').strip().lower()\n    return raw if raw in {'least_loaded', 'weighted'} else 'least_loaded'\n\n\ndef parse_instances():\n    diagnostics = {'legacy_token_used': False, 'source': None}\n    default_limit = parse_positive_int(os.environ.get('ACUNETIX_MAX_SCANS_PER_NODE'), 5)\n    raw = (os.environ.get('ACUNETIX_INSTANCES_JSON') or '').strip()\n    instances = []\n    had_instances_payload = bool(raw)\n    if raw:\n        try:\n            arr = json.loads(raw)\n            if isinstance(arr, list):\n                for idx, item in enumerate(arr):\n                    if not isinstance(item, dict):\n                        continue\n                    endpoint = str(item.get('endpoint') or '').strip().rstrip('/')\n                    token = str(item.get('api_key') or item.get('token') or '').strip()\n                    if not endpoint or not token:\n                        continue\n                    node_limit = parse_positive_int(\n                        item.get('max_scans_per_node', item.get('scan_limit', default_limit)),\n                        default_limit,\n                    )\n                    weight = parse_positive_int(item.get('weight', 1), 1)\n                    instances.append({\n                        'name': item.get('name') or f'acu-{idx+1}',\n                        'endpoint': endpoint,\n                        'api_key': token,\n                        'token': token,\n                        'max_scans_per_node': node_limit,\n                        'weight': weight,\n                    })\n        except Exception:\n            pass\n    if not instances:\n        endpoint = (os.environ.get('ACUNETIX_BASE_URL') or 'https://localhost:3443').strip().rstrip('/')\n        primary_token = (os.environ.get('ACUNETIX_API_KEY') or '').strip()\n        legacy_token = (os.environ.get('ACU_API_TOKEN') or '').strip()\n        token = primary_token or legacy_token\n        diagnostics['legacy_token_used'] = bool((not primary_token) and legacy_token)\n        if token:\n            diagnostics['source'] = 'env_default'\n            instances.append({\n                'name': 'acu-default',\n                'endpoint': endpoint,\n                'api_key': token,\n                'token': token,\n                'max_scans_per_node': default_limit,\n                'weight': 1,\n            })\n    if instances and diagnostics['source'] is None:\n        diagnostics['source'] = 'instances_json'\n    if had_instances_payload and not instances:\n        raise Exception('WF_D_PT_AcunetixScan stage config error: ACUNETIX_INSTANCES_JSON is set but has no valid nodes with endpoint+api_key/token. Use ACUNETIX_API_KEY (legacy fallback: ACU_API_TOKEN) or fix instances JSON.')\n    if not instances:\n        raise Exception('WF_D_PT_AcunetixScan stage config error: Acunetix API key is empty. Set ACUNETIX_API_KEY (temporary fallback: ACU_API_TOKEN) before running dispatch stage.')\n    return instances, diagnostics\n\n\ndef http_json(url, token, timeout=8):\n    req = urllib.request.Request(url)\n    req.add_header('X-Auth', token)\n    with urllib.request.urlopen(req, timeout=timeout) as resp:\n        data = resp.read().decode('utf-8')\n        return getattr(resp, 'status', 200), json.loads(data) if data else {}\n\n\ndef pick_by_policy(candidates, policy):\n    if not candidates:\n        return None\n    if policy == 'weighted':\n        return sorted(\n            candidates,\n            key=lambda n: (\n                (n['active_sessions'] + n['planned']) / max(1, int(n.get('weight', 1))),\n                n['active_sessions'] + n['planned'],\n                n['name'],\n            ),\n        )[0]\n    return sorted(\n        candidates,\n        key=lambda n: (\n            n['active_sessions'] + n['planned'],\n            n['active_sessions'],\n            n['planned'],\n            n['name'],\n        ),\n    )[0]\n\n\n\n\ndef load_target_mapping(path):\n    if not path:\n        return {}\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            payload = json.load(f)\n        items = payload.get('items', {}) if isinstance(payload, dict) else {}\n        if isinstance(items, dict):\n            return items\n    except Exception:\n        return {}\n    return {}\n\n\n\ndef normalize_target_mapping(raw):\n    if not isinstance(raw, dict):\n        return {}\n    out = {}\n    for product_id, row in raw.items():\n        key = str(product_id)\n        if isinstance(row, dict):\n            target_id = row.get('target_id')\n        else:\n            target_id = row\n        target_id = str(target_id or '').strip()\n        if not target_id:\n            continue\n        out[key] = {'dojo_product_id': key, 'acunetix_target_id': target_id, 'target_id': target_id}\n    return out\n\n\ndef normalize_selected_node(raw):\n    if not isinstance(raw, dict):\n        return None\n    endpoint = str(raw.get('endpoint') or '').strip().rstrip('/')\n    token = str(raw.get('api_key') or raw.get('token') or '').strip()\n    if not endpoint or not token:\n        return None\n    return {'name': str(raw.get('name') or 'acu-selected').strip() or 'acu-selected', 'endpoint': endpoint, 'api_key': token, 'token': token}\n\n\ndef load_pt_node_mapping(path):\n    if not path:\n        return {}\n    try:\n        with open(path, 'r', encoding='utf-8') as f:\n            payload = json.load(f)\n        items = payload.get('items', {}) if isinstance(payload, dict) else {}\n        return items if isinstance(items, dict) else {}\n    except Exception:\n        return {}\n\n\ndef sticky_node_for_pt(pt_id, nodes):\n    ordered = sorted(nodes, key=lambda n: n['name'])\n    if not ordered:\n        return None\n    digest = hashlib.sha256(str(pt_id).encode('utf-8')).hexdigest()\n    index = int(digest[:8], 16) % len(ordered)\n    return ordered[index]['name']\n\n\ntrigger_input = $node['Trigger'].json if isinstance($node['Trigger'].json, dict) else {}\ntrigger_product_type_id = trigger_input.get('product_type_id')\ntrigger_pt_id = trigger_input.get('pt_id', trigger_product_type_id)\ntrigger_stage = str(trigger_input.get('stage') or 'acu')\ntrigger_domain = trigger_input.get('domain')\ntrigger_job_metadata = trigger_input.get('job_metadata') if isinstance(trigger_input.get('job_metadata'), dict) else {}\ntrigger_selected_node = normalize_selected_node(trigger_input.get('selected_acu_node'))\ntry:\n    trigger_product_type_id = int(trigger_product_type_id) if trigger_product_type_id is not None else None\nexcept Exception:\n    trigger_product_type_id = None\n\nselection_policy = normalize_policy(os.environ.get('ACUNETIX_NODE_SELECTION_POLICY'))\nsticky_assignment = parse_bool(os.environ.get('ACUNETIX_STICKY_ASSIGNMENT', 'true'), True)\nfairness_policy = 'round_robin_by_pt'\n\nresponse_payload = $node['Get PT Targets/Products'].json if isinstance($node['Get PT Targets/Products'].json, dict) else {}\nproducts = list(response_payload.get('results') or [])\n\ndef fetch_next_pages(initial_next):\n    token = (os.environ.get('DOJO_API_TOKEN') or '').strip()\n    if not initial_next or not token:\n        return []\n    out = []\n    visited = set()\n    current = str(initial_next)\n    while current and current not in visited:\n        visited.add(current)\n        req = urllib.request.Request(current)\n        req.add_header('Authorization', f'Token {token}')\n        req.add_header('Accept', 'application/json')\n        with urllib.request.urlopen(req, timeout=15) as resp:\n            payload = json.loads(resp.read().decode('utf-8') or '{}')\n        out.extend(payload.get('results') or [])\n        current = payload.get('next')\n    return out\n\nproducts.extend(fetch_next_pages(response_payload.get('next')))\ntrigger_mapping = normalize_target_mapping(trigger_input.get('dojo_product_to_acunetix_target_mapping') or trigger_input.get('target_mapping'))\nmapping_items = trigger_mapping or load_target_mapping(MAPPING_FILE)\npt_node_mapping = load_pt_node_mapping(PT_NODE_MAPPING_FILE)\neligible = []\nskipped_without_target_id = []\nfor p in products:\n    if not isinstance(p, dict):\n        continue\n    try:\n        product_type_id = int(p.get('prod_type'))\n    except Exception:\n        continue\n    if trigger_product_type_id is not None and product_type_id != trigger_product_type_id:\n        continue\n    tags = p.get('tags') or []\n    if not isinstance(tags, list):\n        tags = [str(tags)]\n    tag_signals = {\n        'targets_ready_tag': 'targets:ready' in tags,\n        'acunetix_active_tag': 'acunetix:active' in tags,\n    }\n    if trigger_stage != 'acu':\n        continue\n    mapping_row = mapping_items.get(str(p.get('id'))) if isinstance(mapping_items, dict) else {}\n    target_id = None\n    acunetix_target_id = None\n    if isinstance(mapping_row, dict):\n        target_id = mapping_row.get('target_id')\n        acunetix_target_id = mapping_row.get('acunetix_target_id')\n    elif isinstance(mapping_row, str):\n        target_id = mapping_row\n        acunetix_target_id = mapping_row\n\n    target_id = str(target_id or '').strip()\n    acunetix_target_id = str(acunetix_target_id or '').strip()\n    resolved_target_id = acunetix_target_id or target_id\n    if not resolved_target_id:\n        skipped_without_target_id.append({\n            'product_id': p.get('id'),\n            'product_name': p.get('name'),\n            'product_type_id': product_type_id,\n            'pt_id': trigger_pt_id if trigger_pt_id is not None else product_type_id,\n            'stage': 'acu',\n            'reason': 'missing_target_id',\n            'target_id': target_id,\n            'acunetix_target_id': acunetix_target_id,\n        })\n        continue\n\n    eligible.append({\n        'product_id': p.get('id'),\n        'product_name': p.get('name'),\n        'product_type_id': product_type_id,\n        'pt_id': trigger_pt_id if trigger_pt_id is not None else product_type_id,\n        'stage': 'acu',\n        'domain': trigger_domain,\n        'job_metadata': trigger_job_metadata,\n        'tag_signals': tag_signals,\n        'target_id': resolved_target_id,\n        'acunetix_target_id': resolved_target_id,\n    })\n\n# Fairness: round-robin by PT so one PT does not consume all slots.\npt_queues = {}\nfor item in sorted(eligible, key=lambda x: (int(x.get('product_id') or 0), int(x.get('product_type_id') or 0))):\n    pt_queues.setdefault(int(item['product_type_id']), []).append(item)\npt_order = sorted(pt_queues.keys())\n\ninstances, token_diagnostics = parse_instances()\nnode_reports = []\navailable_nodes = []\ntotal_active = 0\nfor node in instances:\n    report = dict(node)\n    try:\n        status, _ = http_json(node['endpoint'] + '/api/v1/me', node['token'])\n        if status < 200 or status > 299:\n            raise Exception(f'health_status_{status}')\n        _, scans = http_json(node['endpoint'] + '/api/v1/scans?l=100', node['token'])\n        active_sessions = 0\n        for s in scans.get('scans', []) or []:\n            st = (s.get('current_session') or {}).get('status', '')\n            if st in ACTIVE_STATUSES:\n                active_sessions += 1\n        free_slots = max(0, int(node['max_scans_per_node']) - active_sessions)\n        report.update({\n            'healthy': True,\n            'active_sessions': active_sessions,\n            'free_slots': free_slots,\n        })\n        total_active += active_sessions\n        if free_slots > 0:\n            available_nodes.append({**node, 'active_sessions': active_sessions, 'free_slots': free_slots, 'planned': 0})\n    except Exception as e:\n        report.update({'healthy': False, 'active_sessions': None, 'free_slots': 0, 'error': str(e)})\n    node_reports.append(report)\n\nselected = []\nselected_by_pt = {}\nlog_events = []\nresync_required_pts = []\nfor rep in node_reports:\n    log_events.append({\n        'pt_id': None,\n        'stage': 'acu_pool_probe',\n        'job_id': rep.get('name'),\n        'server': rep.get('endpoint') or rep.get('name'),\n        'status': 'ok' if rep.get('healthy') else 'error',\n        'duration': None,\n    })\nif available_nodes and pt_order:\n    cursor = 0\n    while True:\n        candidates = [n for n in available_nodes if n['free_slots'] > 0]\n        if not candidates:\n            break\n        active_pts = [pt for pt in pt_order if pt_queues.get(pt)]\n        if not active_pts:\n            break\n\n        pt_id = active_pts[cursor % len(active_pts)]\n        cursor += 1\n        item = pt_queues[pt_id].pop(0)\n\n        chosen = None\n        sticky_name = None\n        pinned = trigger_selected_node if trigger_selected_node and int(item.get('pt_id') or 0) == int(trigger_pt_id or item.get('pt_id') or 0) else normalize_selected_node(pt_node_mapping.get(str(pt_id)))\n        if pinned:\n            pinned_candidate = next((n for n in candidates if str(n.get('endpoint', '')).rstrip('/') == str(pinned.get('endpoint', '')).rstrip('/')), None)\n            if pinned_candidate is not None:\n                chosen = pinned_candidate\n            else:\n                fallback_choice = pick_by_policy(candidates, selection_policy)\n                resync_required_pts.append({'pt_id': pt_id, 'previous_node': pinned, 'fallback_node': {'name': fallback_choice.get('name'), 'endpoint': fallback_choice.get('endpoint')} if fallback_choice else None, 'reason': 'pinned_node_unavailable', 'policy': 'resync_targets_before_scan'})\n                log_events.append({'pt_id': pt_id, 'stage': 'acu_dispatch', 'job_id': item.get('product_id'), 'server': pinned.get('name') or pinned.get('endpoint'), 'status': 'pinned_node_unavailable_requires_resync', 'duration': None})\n                continue\n        if sticky_assignment:\n            sticky_name = sticky_node_for_pt(pt_id, candidates)\n            if sticky_name:\n                sticky_candidate = next((n for n in candidates if n['name'] == sticky_name), None)\n                if sticky_candidate is not None:\n                    chosen = sticky_candidate\n\n        if chosen is None:\n            chosen = pick_by_policy(candidates, selection_policy)\n\n        if chosen is None:\n            break\n\n        item.update({\n            'selected_acu_node': {\n                'name': chosen['name'],\n                'endpoint': chosen['endpoint'],\n                'api_key': chosen['api_key'],\n                'token': chosen['token'],\n            },\n            'acunetix_node_name': chosen['name'],\n            'acunetix_endpoint': chosen['endpoint'],\n            'acunetix_api_key': chosen['api_key'],\n            'acunetix_token': chosen['token'],\n            'dispatch_policy': {\n                'fairness': fairness_policy,\n                'node_selection': selection_policy,\n                'sticky_assignment': sticky_assignment,\n                'sticky_node_name': sticky_name if sticky_assignment else None,\n            },\n        })\n        log_events.append({\n            'pt_id': pt_id,\n            'stage': 'acu_dispatch',\n            'job_id': item.get('product_id'),\n            'server': chosen.get('name'),\n            'status': 'queued',\n            'duration': None,\n        })\n        selected.append(item)\n        selected_by_pt[str(pt_id)] = int(selected_by_pt.get(str(pt_id), 0)) + 1\n        chosen['planned'] += 1\n        chosen['free_slots'] -= 1\n\nreturn [{\n  'json': {\n    'active_scans': total_active,\n    'scan_limit': sum(int(n.get('max_scans_per_node', 0)) for n in instances),\n    'available_slots': sum(max(0, int(n.get('free_slots', 0))) for n in node_reports if n.get('healthy')),\n    'dispatch_count': len(selected),\n    'dispatch_items': selected,\n    'skipped_without_target_id': skipped_without_target_id,\n    'dispatch_by_pt': selected_by_pt,\n    'dispatch_policy': {\n        'fairness': fairness_policy,\n        'node_selection': selection_policy,\n        'sticky_assignment': sticky_assignment,\n    },\n    'acunetix_pool': node_reports,\n    'target_mapping_file': MAPPING_FILE,\n    'log_events': log_events,\n    'resync_required_pts': resync_required_pts,\n    'token_diagnostics': token_diagnostics,\n  }\n}]"
      },
      "id": "d-plan",
      "name": "Build Dispatch Plan (Python)",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -540,
        160
      ]
    },
    {
      "parameters": {
        "conditions": {
          "number": [
            {
              "value1": "={{ $json.dispatch_count }}",
              "operation": "larger",
              "value2": 0
            }
          ]
        }
      },
      "id": "d-if",
      "name": "Has capacity and products?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 1,
      "position": [
        -340,
        160
      ]
    },
    {
      "parameters": {
        "language": "python",
        "pythonCode": "out = []\nfor row in $json.get('dispatch_items', []):\n    if not isinstance(row, dict):\n        continue\n    out.append({'json': {\n        'pt_id': row.get('pt_id', row.get('product_type_id')),\n        'product_id': row.get('product_id'),\n        'product_name': row.get('product_name'),\n        'product_type_id': row.get('product_type_id'),\n        'domain': row.get('domain'),\n        'stage': row.get('stage', 'acu'),\n        'target_id': row.get('target_id') or row.get('acunetix_target_id'),\n        'acunetix_target_id': row.get('acunetix_target_id') or row.get('target_id'),\n        'job_metadata': row.get('job_metadata', {}),\n        'selected_acu_node': row.get('selected_acu_node'),\n        'acunetix_node_name': row.get('acunetix_node_name'),\n        'acunetix_endpoint': row.get('acunetix_endpoint'),\n        'acunetix_api_key': row.get('acunetix_api_key', row.get('acunetix_token')),\n        'acunetix_token': row.get('acunetix_token', row.get('acunetix_api_key')),\n\n        'tag_signals': row.get('tag_signals', {}),\n    }})\nreturn out"
      },
      "id": "d-expand",
      "name": "Expand Dispatch Items",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -120,
        80
      ]
    },
    {
      "parameters": {
        "workflowId": "WF_D_ProductScan",
        "options": {
          "waitForSubWorkflow": true
        }
      },
      "id": "d-run-product",
      "name": "Run WF_D_ProductScan",
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1,
      "position": [
        100,
        80
      ],
      "continueOnFail": false
    }
  ],
  "connections": {
    "Trigger": {
      "main": [
        [
          {
            "node": "Get PT Targets/Products",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get PT Targets/Products": {
      "main": [
        [
          {
            "node": "Get Active Acunetix Scans",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Active Acunetix Scans": {
      "main": [
        [
          {
            "node": "Build Dispatch Plan (Python)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Dispatch Plan (Python)": {
      "main": [
        [
          {
            "node": "Has capacity and products?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has capacity and products?": {
      "main": [
        [
          {
            "node": "Expand Dispatch Items",
            "type": "main",
            "index": 0
          }
        ],
        []
      ]
    },
    "Expand Dispatch Items": {
      "main": [
        [
          {
            "node": "Run WF_D_ProductScan",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "tags": []
}