{
  "name": "WF_D_PT_AcunetixScan",
  "nodes": [
    {
      "parameters": {},
      "id": "d-trigger",
      "name": "Trigger",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1,
      "position": [
        -1180,
        160
      ]
    },
    {
      "parameters": {
        "authentication": "headerAuth",
        "url": "={{ ($env.DOJO_BASE_URL || 'http://localhost:8080/api/v2').replace(/\\/+$/,'') + '/products/?tags=targets:ready&limit=200&offset=0' }}",
        "options": {
          "allowUnauthorizedCerts": true
        }
      },
      "id": "d-products",
      "name": "Get PT Targets/Products",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        -980,
        160
      ],
      "credentials": {
        "httpHeaderAuth": {
          "id": "mGl4PbJkKfeJbTg8",
          "name": "Header Auth account"
        }
      }
    },
    {
      "parameters": {
        "keepOnlySet": true,
        "values": {
          "string": [
            {
              "name": "pool_probe",
              "value": "started"
            }
          ]
        },
        "options": {}
      },
      "id": "d-acu-scans",
      "name": "Get Active Acunetix Scans",
      "type": "n8n-nodes-base.set",
      "typeVersion": 2,
      "position": [
        -760,
        160
      ]
    },
    {
      "parameters": {
        "language": "python",
        "pythonCode": "import os\nimport json\nimport urllib.request\nimport urllib.error\nimport hashlib\nimport urllib.parse\nimport re\nimport sqlite3\nfrom datetime import datetime, timezone\nimport ssl\n\n# Intentional policy: internal services may use self-signed certs; TLS verification is disabled on purpose.\nSSL_UNVERIFIED_CONTEXT = ssl._create_unverified_context()\n\nMAPPING_DB_PATH = (os.environ.get('ACUNETIX_MAPPING_DB') or '/data/n8n/acunetix_mapping_store.sqlite3').strip()\nif not MAPPING_DB_PATH.startswith('/data/'):\n    raise Exception(f\"ACUNETIX_MAPPING_DB must point to /data/... (got: {MAPPING_DB_PATH})\")\nmapping_backend = {'backend': 'sqlite', 'path': MAPPING_DB_PATH, 'role': 'required'}\n\nACTIVE_STATUSES = {'processing', 'scheduled', 'queued', 'starting'}\nTARGET_ID_PATTERN = re.compile(r'[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[1-5][0-9a-fA-F]{3}-[89abAB][0-9a-fA-F]{3}-[0-9a-fA-F]{12}')\n\n\ndef is_valid_target_id(value):\n    return bool(TARGET_ID_PATTERN.fullmatch(str(value or '').strip()))\n\n\ndef parse_positive_int(value, default):\n    try:\n        parsed = int(value)\n        if parsed > 0:\n            return parsed\n    except Exception:\n        pass\n    return default\n\n\ndef parse_bool(value, default=False):\n    if value is None:\n        return default\n    if isinstance(value, bool):\n        return value\n    raw = str(value).strip().lower()\n    if raw in {'1', 'true', 'yes', 'y', 'on'}:\n        return True\n    if raw in {'0', 'false', 'no', 'n', 'off'}:\n        return False\n    return default\n\n\ndef normalize_policy(value):\n    raw = str(value or '').strip().lower()\n    return raw if raw in {'least_loaded', 'weighted'} else 'least_loaded'\n\n\ndef parse_instances():\n    diagnostics = {'source': None}\n    default_limit = parse_positive_int(os.environ.get('ACUNETIX_MAX_SCANS_PER_NODE'), 5)\n    raw = (os.environ.get('ACUNETIX_INSTANCES_JSON') or '').strip()\n    raw_sanitized = raw\n    if raw_sanitized.startswith('\"') and raw_sanitized.endswith('\"'):\n        raw_sanitized = raw_sanitized[1:-1].strip()\n    instances = []\n    had_instances_payload = bool(raw)\n    if raw_sanitized:\n        try:\n            arr = json.loads(raw_sanitized)\n            if isinstance(arr, list):\n                for idx, item in enumerate(arr):\n                    if not isinstance(item, dict):\n                        continue\n                    endpoint = str(item.get('endpoint') or '').strip().rstrip('/')\n                    token = str(item.get('api_key') or '').strip()\n                    if not endpoint or not token:\n                        continue\n                    node_limit = parse_positive_int(\n                        item.get('max_scans_per_node', default_limit),\n                        default_limit,\n                    )\n                    weight = parse_positive_int(item.get('weight', 1), 1)\n                    instances.append({\n                        'name': item.get('name') or f'acu-{idx+1}',\n                        'endpoint': endpoint,\n                        'api_key': token,\n                        'max_scans_per_node': node_limit,\n                        'weight': weight,\n                    })\n        except Exception:\n            pass\n    if not instances:\n        endpoint = (os.environ.get('ACUNETIX_BASE_URL') or 'https://localhost:3443').strip().rstrip('/')\n        primary_token = (os.environ.get('ACUNETIX_API_KEY') or '').strip()\n        token = primary_token\n        if token:\n            diagnostics['source'] = 'env_default'\n            instances.append({\n                'name': 'acu-default',\n                'endpoint': endpoint,\n                'api_key': token,\n                'max_scans_per_node': default_limit,\n                'weight': 1,\n            })\n    if instances and diagnostics['source'] is None:\n        diagnostics['source'] = 'instances_json'\n    if had_instances_payload and not instances:\n        raise Exception('WF_D_PT_AcunetixScan stage config error: ACUNETIX_INSTANCES_JSON is set but has no valid nodes with endpoint+api_key. Use ACUNETIX_API_KEY or fix instances JSON.')\n    if not instances:\n        raise Exception('WF_D_PT_AcunetixScan stage config error: Acunetix API key is empty. Set ACUNETIX_API_KEY before running dispatch stage.')\n    return instances, diagnostics\n\n\ndef http_json(url, token, timeout=8):\n    req = urllib.request.Request(url)\n    req.add_header('X-Auth', token)\n    with urllib.request.urlopen(req, timeout=timeout, context=SSL_UNVERIFIED_CONTEXT) as resp:\n        data = resp.read().decode('utf-8')\n        return getattr(resp, 'status', 200), json.loads(data) if data else {}\n\n\ndef pick_by_policy(candidates, policy):\n    if not candidates:\n        return None\n    if policy == 'weighted':\n        return sorted(\n            candidates,\n            key=lambda n: (\n                (n['active_sessions'] + n['planned']) / max(1, int(n.get('weight', 1))),\n                n['active_sessions'] + n['planned'],\n                n['name'],\n            ),\n        )[0]\n    return sorted(\n        candidates,\n        key=lambda n: (\n            n['active_sessions'] + n['planned'],\n            n['active_sessions'],\n            n['planned'],\n            n['name'],\n        ),\n    )[0]\n\n\n\ndef normalize_selected_node(raw):\n    if not isinstance(raw, dict):\n        return None\n    try:\n        weight = max(1, int(raw.get('weight', 1) or 1))\n    except Exception:\n        weight = 1\n    return {\n        'endpoint': str(raw.get('endpoint') or '').strip().rstrip('/'),\n        'name': str(raw.get('name') or 'acu-selected').strip() or 'acu-selected',\n        'weight': weight,\n    }\n\n\ndef nodes_equal(lhs, rhs):\n    return isinstance(lhs, dict) and isinstance(rhs, dict) and str(lhs.get('endpoint') or '').strip().rstrip('/') == str(rhs.get('endpoint') or '').strip().rstrip('/') and str(lhs.get('name') or '').strip() == str(rhs.get('name') or '').strip()\n\n\ndef init_db(conn):\n    conn.execute(\"\"\"\n        CREATE TABLE IF NOT EXISTS acunetix_mapping (\n            pt_id TEXT NOT NULL,\n            product_id TEXT NOT NULL,\n            selected_acu_node TEXT,\n            target_id TEXT,\n            updated_at TEXT NOT NULL,\n            PRIMARY KEY (pt_id, product_id)\n        )\n    \"\"\")\n\n\ndef now_iso():\n    return datetime.now(timezone.utc).isoformat()\n\n\ndef load_mapping_store(path):\n    target_map = {}\n    pt_nodes = {}\n    mapping_secret_violations = []\n    if not path:\n        return target_map, pt_nodes, mapping_secret_violations\n    try:\n        conn = sqlite3.connect(path, timeout=30)\n        with conn:\n            init_db(conn)\n            for pt_id, product_id, selected_raw, target_id, updated_at in conn.execute(\"SELECT pt_id, product_id, selected_acu_node, target_id, updated_at FROM acunetix_mapping\"):\n                pid = str(product_id or '').strip()\n                tid = str(target_id or '').strip()\n                if pid and tid and pid not in target_map:\n                    target_map[pid] = {'dojo_product_id': pid, 'acunetix_target_id': tid, 'target_id': tid, 'pt_id': str(pt_id or '')}\n                if selected_raw and str(pt_id or '').strip():\n                    try:\n                        node = json.loads(selected_raw)\n                    except Exception:\n                        node = None\n                    if isinstance(node, dict) and any(k in node for k in ('api_key', 'token')):\n                        mapping_secret_violations.append({'pt_id': str(pt_id or ''), 'product_id': pid, 'fields': [k for k in ('api_key', 'token') if k in node]})\n                    node = normalize_selected_node(node)\n                    if isinstance(node, dict):\n                        prev = pt_nodes.get(str(pt_id))\n                        if (not prev) or str(updated_at or '') >= str(prev.get('_updated_at') or ''):\n                            node['_updated_at'] = str(updated_at or '')\n                            pt_nodes[str(pt_id)] = node\n        conn.close()\n    except Exception:\n        return target_map, pt_nodes, mapping_secret_violations\n    for k,v in list(pt_nodes.items()):\n        v.pop('_updated_at', None)\n    return target_map, pt_nodes, mapping_secret_violations\n\n\ndef upsert_dispatch_items(path, items):\n    if not path or not isinstance(items, list) or not items:\n        return 0\n    count = 0\n    conn = sqlite3.connect(path, timeout=30)\n    with conn:\n        init_db(conn)\n        ts = now_iso()\n        for item in items:\n            pt_id = str(item.get('pt_id') or item.get('product_type_id') or '').strip()\n            product_id = str(item.get('product_id') or '').strip()\n            target_id = str(item.get('target_id') or item.get('acunetix_target_id') or '').strip()\n            node = normalize_selected_node(item.get('selected_acu_node'))\n            if not pt_id or not product_id:\n                continue\n            conn.execute(\"INSERT INTO acunetix_mapping(pt_id,product_id,selected_acu_node,target_id,updated_at) VALUES(?,?,?,?,?) ON CONFLICT(pt_id,product_id) DO UPDATE SET selected_acu_node=excluded.selected_acu_node,target_id=excluded.target_id,updated_at=excluded.updated_at\", (pt_id, product_id, json.dumps({'name': node.get('name'), 'endpoint': node.get('endpoint'), 'weight': node.get('weight',1)}, ensure_ascii=False) if node else None, target_id, ts))\n            count += 1\n    conn.close()\n    return count\n\n\ndef sticky_node_for_pt(pt_id, nodes):\n    ordered = sorted(nodes, key=lambda n: n['name'])\n    if not ordered:\n        return None\n    digest = hashlib.sha256(str(pt_id).encode('utf-8')).hexdigest()\n    index = int(digest[:8], 16) % len(ordered)\n    return ordered[index]['name']\n\n\ntrigger_input = _('Trigger').first().json if _('Trigger').first() and isinstance(_('Trigger').first().json, dict) else {}\ntrigger_product_type_id = trigger_input.get('product_type_id')\ntrigger_pt_id = trigger_input.get('pt_id', trigger_product_type_id)\ntrigger_stage = str(trigger_input.get('stage') or 'acu')\ntrigger_domain = trigger_input.get('domain')\ntrigger_job_metadata = trigger_input.get('job_metadata') if isinstance(trigger_input.get('job_metadata'), dict) else {}\ntrigger_selected_node = normalize_selected_node(trigger_input.get('selected_acu_node'))\ntry:\n    trigger_product_type_id = int(trigger_product_type_id) if trigger_product_type_id is not None else None\nexcept Exception:\n    trigger_product_type_id = None\n\nselection_policy = normalize_policy(os.environ.get('ACUNETIX_NODE_SELECTION_POLICY'))\nsticky_assignment = parse_bool(os.environ.get('ACUNETIX_STICKY_ASSIGNMENT', 'true'), True)\nfairness_policy = 'round_robin_by_pt'\n\nresponse_payload = _('Get PT Targets/Products').first().json if _('Get PT Targets/Products').first() and isinstance(_('Get PT Targets/Products').first().json, dict) else {}\nproducts = list(response_payload.get('results') or [])\n\ndef fetch_next_pages(initial_next):\n    token = (os.environ.get('DOJO_API_TOKEN') or '').strip()\n    if not initial_next or not token:\n        return []\n    out = []\n    visited = set()\n    current = str(initial_next)\n    while current and current not in visited:\n        visited.add(current)\n        req = urllib.request.Request(current)\n        req.add_header('Authorization', f'Token {token}')\n        req.add_header('Accept', 'application/json')\n        with urllib.request.urlopen(req, timeout=15, context=SSL_UNVERIFIED_CONTEXT) as resp:\n            payload = json.loads(resp.read().decode('utf-8') or '{}')\n        out.extend(payload.get('results') or [])\n        current = payload.get('next')\n    return out\n\nproducts.extend(fetch_next_pages(response_payload.get('next')))\ntrigger_mapping = normalize_target_mapping(trigger_input.get('dojo_product_to_acunetix_target_mapping') or trigger_input.get('target_mapping'))\ndb_target_mapping, pt_node_mapping, mapping_secret_violations = load_mapping_store(MAPPING_DB_PATH)\nmapping_items = trigger_mapping or db_target_mapping\neligible = []\nskipped_without_target_id = []\nfor p in products:\n    if not isinstance(p, dict):\n        continue\n    try:\n        product_type_id = int(p.get('prod_type'))\n    except Exception:\n        continue\n    if trigger_product_type_id is not None and product_type_id != trigger_product_type_id:\n        continue\n    tags = p.get('tags') or []\n    if not isinstance(tags, list):\n        tags = [str(tags)]\n    tag_signals = {\n        'targets_ready_tag': 'targets:ready' in tags,\n        'acunetix_active_tag': 'acunetix:active' in tags,\n    }\n    if trigger_stage != 'acu':\n        continue\n    mapping_row = mapping_items.get(str(p.get('id'))) if isinstance(mapping_items, dict) else {}\n    target_id = None\n    acunetix_target_id = None\n    if isinstance(mapping_row, dict):\n        target_id = mapping_row.get('target_id')\n        acunetix_target_id = mapping_row.get('acunetix_target_id')\n    elif isinstance(mapping_row, str):\n        target_id = mapping_row\n        acunetix_target_id = mapping_row\n\n    target_id = str(target_id or '').strip()\n    acunetix_target_id = str(acunetix_target_id or '').strip()\n    resolved_target_id = acunetix_target_id or target_id\n    valid_target_id = is_valid_target_id(resolved_target_id)\n    if not resolved_target_id or not valid_target_id:\n        skipped_without_target_id.append({\n            'product_id': p.get('id'),\n            'product_name': p.get('name'),\n            'product_type_id': product_type_id,\n            'pt_id': trigger_pt_id if trigger_pt_id is not None else product_type_id,\n            'stage': 'acu',\n            'reason': 'missing_target_id' if not resolved_target_id else 'invalid_target_id',\n            'target_id': target_id,\n            'acunetix_target_id': acunetix_target_id,\n            'resolved_target_id': resolved_target_id,\n        })\n        continue\n\n    eligible.append({\n        'product_id': p.get('id'),\n        'product_name': p.get('name'),\n        'product_type_id': product_type_id,\n        'pt_id': trigger_pt_id if trigger_pt_id is not None else product_type_id,\n        'stage': 'acu',\n        'domain': trigger_domain,\n        'job_metadata': trigger_job_metadata,\n        'tag_signals': tag_signals,\n        'target_id': resolved_target_id,\n        'acunetix_target_id': resolved_target_id,\n    })\n\n# Fairness: round-robin by PT so one PT does not consume all slots.\npt_queues = {}\nfor item in sorted(eligible, key=lambda x: (int(x.get('product_id') or 0), int(x.get('product_type_id') or 0))):\n    pt_queues.setdefault(int(item['product_type_id']), []).append(item)\npt_order = sorted(pt_queues.keys())\n\ninstances, token_diagnostics = parse_instances()\nnode_reports = []\navailable_nodes = []\ntotal_active = 0\nfor node in instances:\n    report = dict(node)\n    try:\n        status, _ = http_json(node['endpoint'] + '/api/v1/me', node['token'])\n        if status < 200 or status > 299:\n            raise Exception(f'health_status_{status}')\n        _, scans = http_json(node['endpoint'] + '/api/v1/scans?l=100', node['token'])\n        active_sessions = 0\n        for s in scans.get('scans', []) or []:\n            st = (s.get('current_session') or {}).get('status', '')\n            if st in ACTIVE_STATUSES:\n                active_sessions += 1\n        free_slots = max(0, int(node['max_scans_per_node']) - active_sessions)\n        report.update({\n            'healthy': True,\n            'active_sessions': active_sessions,\n            'free_slots': free_slots,\n            'mapping_secret_check_ok': len(mapping_secret_violations) == 0,\n        })\n        total_active += active_sessions\n        if free_slots > 0:\n            available_nodes.append({**node, 'active_sessions': active_sessions, 'free_slots': free_slots, 'planned': 0})\n    except Exception as e:\n        report.update({'healthy': False, 'active_sessions': None, 'free_slots': 0, 'error': str(e), 'mapping_secret_check_ok': len(mapping_secret_violations) == 0})\n    node_reports.append(report)\n\nselected = []\nselected_by_pt = {}\nlog_events = []\nresync_required_pts = []\npt_node_reconcile_events = []\npt_node_reconcile_updates = {}\nfor rep in node_reports:\n    log_events.append({\n        'pt_id': None,\n        'stage': 'acu_pool_probe',\n        'job_id': rep.get('name'),\n        'server': rep.get('endpoint') or rep.get('name'),\n        'status': 'ok' if rep.get('healthy') else 'error',\n        'duration': None,\n    })\nif available_nodes and pt_order:\n    cursor = 0\n    while True:\n        candidates = [n for n in available_nodes if n['free_slots'] > 0]\n        if not candidates:\n            break\n        active_pts = [pt for pt in pt_order if pt_queues.get(pt)]\n        if not active_pts:\n            break\n\n        pt_id = active_pts[cursor % len(active_pts)]\n        cursor += 1\n        item = pt_queues[pt_id].pop(0)\n\n        chosen = None\n        sticky_name = None\n        state_primary = trigger_selected_node if trigger_selected_node and int(item.get('pt_id') or 0) == int(trigger_pt_id or item.get('pt_id') or 0) else normalize_selected_node(item.get('selected_acu_node'))\n        cache_node = normalize_selected_node(pt_node_mapping.get(str(pt_id)))\n        if state_primary and cache_node and not nodes_equal(state_primary, cache_node):\n            pt_node_reconcile_events.append({\n                'stage': 'wf_d_pt_acunetixscan',\n                'pt_id': pt_id,\n                'message': 'PTâ†’Acunetix node mismatch detected; secondary cache synchronized from primary node binding.',\n                'primary': {'endpoint': state_primary.get('endpoint'), 'name': state_primary.get('name')},\n                'secondary_before': {'endpoint': cache_node.get('endpoint'), 'name': cache_node.get('name')},\n            })\n            pt_node_reconcile_updates[str(pt_id)] = state_primary\n        pinned = state_primary or cache_node\n        if pinned:\n            pinned_candidate = next((n for n in candidates if str(n.get('endpoint', '')).rstrip('/') == str(pinned.get('endpoint', '')).rstrip('/')), None)\n            if pinned_candidate is not None:\n                chosen = pinned_candidate\n            else:\n                fallback_choice = pick_by_policy(candidates, selection_policy)\n                if fallback_choice is None:\n                    log_events.append({'pt_id': pt_id, 'stage': 'acu_dispatch', 'job_id': item.get('product_id'), 'server': pinned.get('name') or pinned.get('endpoint'), 'status': 'pinned_node_unavailable_no_fallback_capacity', 'duration': None})\n                    continue\n                chosen = fallback_choice\n                item['requires_target_resync'] = True\n                item['resync_reason'] = 'pinned_node_unavailable'\n                item['previous_selected_acu_node'] = pinned\n                resync_required_pts.append({'pt_id': pt_id, 'product_id': item.get('product_id'), 'previous_node': pinned, 'fallback_node': {'name': chosen.get('name'), 'endpoint': chosen.get('endpoint')}, 'reason': 'pinned_node_unavailable', 'policy': 'resync_targets_before_scan'})\n                log_events.append({'pt_id': pt_id, 'stage': 'acu_dispatch', 'job_id': item.get('product_id'), 'server': pinned.get('name') or pinned.get('endpoint'), 'status': 'pinned_node_unavailable_fallback_selected', 'duration': None})\n        if sticky_assignment:\n            sticky_name = sticky_node_for_pt(pt_id, candidates)\n            if sticky_name:\n                sticky_candidate = next((n for n in candidates if n['name'] == sticky_name), None)\n                if sticky_candidate is not None:\n                    chosen = sticky_candidate\n\n        if chosen is None:\n            chosen = pick_by_policy(candidates, selection_policy)\n\n        if chosen is None:\n            break\n\n        item.update({\n            'requires_target_resync': bool(item.get('requires_target_resync')),\n            'resync_reason': item.get('resync_reason'),\n            'previous_selected_acu_node': item.get('previous_selected_acu_node'),\n            'selected_acu_node': {\n                'name': chosen['name'],\n                'endpoint': chosen['endpoint'],\n                'weight': chosen.get('weight', 1),\n            },\n            'acunetix_node_name': chosen['name'],\n            'acunetix_endpoint': chosen['endpoint'],\n            'acunetix_api_key': chosen['api_key'],\n                        'dispatch_policy': {\n                'fairness': fairness_policy,\n                'node_selection': selection_policy,\n                'sticky_assignment': sticky_assignment,\n                'sticky_node_name': sticky_name if sticky_assignment else None,\n            },\n        })\n        log_events.append({\n            'pt_id': pt_id,\n            'stage': 'acu_dispatch',\n            'job_id': item.get('product_id'),\n            'server': chosen.get('name'),\n            'status': 'queued',\n            'duration': None,\n        })\n        selected.append(item)\n        selected_by_pt[str(pt_id)] = int(selected_by_pt.get(str(pt_id), 0)) + 1\n        chosen['planned'] += 1\n        chosen['free_slots'] -= 1\n\nmapping_upserts = upsert_dispatch_items(MAPPING_DB_PATH, selected)\n\nreturn [{\n  'json': {\n    'active_scans': total_active,\n    'scan_limit': sum(int(n.get('max_scans_per_node', 0)) for n in instances),\n    'available_slots': sum(max(0, int(n.get('free_slots', 0))) for n in node_reports if n.get('healthy')),\n    'dispatch_count': len(selected),\n    'dispatch_items': selected,\n    'skipped_without_target_id': skipped_without_target_id,\n    'dispatch_by_pt': selected_by_pt,\n    'dispatch_policy': {\n        'fairness': fairness_policy,\n        'node_selection': selection_policy,\n        'sticky_assignment': sticky_assignment,\n    },\n    'acunetix_pool': node_reports,\n    'target_mapping_store': MAPPING_DB_PATH,\n    'mapping_backend': mapping_backend,\n    'mapping_upserts': mapping_upserts,\n    'log_events': log_events,\n    'resync_required_pts': resync_required_pts,\n    'token_diagnostics': token_diagnostics,\n    'pt_node_reconcile_events': pt_node_reconcile_events,\n    'mapping_secret_check': {'ok': len(mapping_secret_violations) == 0, 'violations': mapping_secret_violations},\n  }\n}]"
      },
      "id": "d-plan",
      "name": "Build Dispatch Plan (Python)",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -540,
        160
      ]
    },
    {
      "parameters": {
        "conditions": {
          "number": [
            {
              "value1": "={{ $json.dispatch_count }}",
              "operation": "larger",
              "value2": 0
            }
          ]
        }
      },
      "id": "d-if",
      "name": "Has capacity and products?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 1,
      "position": [
        -340,
        160
      ]
    },
    {
      "parameters": {
        "operation": "splitOut",
        "fieldToSplitOut": "dispatch_items",
        "options": {}
      },
      "id": "d-expand",
      "name": "Expand Dispatch Items (Items)",
      "type": "n8n-nodes-base.itemLists",
      "typeVersion": 3,
      "position": [
        -120,
        80
      ]
    },
    {
      "parameters": {
        "workflowId": "WF_D_ProductScan",
        "options": {
          "waitForSubWorkflow": true
        }
      },
      "id": "d-run-product",
      "name": "Run WF_D_ProductScan",
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1,
      "position": [
        100,
        80
      ],
      "continueOnFail": false
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.requires_target_resync === true }}"
            }
          ]
        }
      },
      "id": "d-if-resync",
      "name": "Needs target resync?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 1,
      "position": [
        100,
        220
      ]
    },
    {
      "parameters": {
        "workflowId": "WF_C_Targets_For_PT",
        "options": {
          "waitForSubWorkflow": true
        }
      },
      "id": "d-run-wfc",
      "name": "Run WF_C_Targets_For_PT",
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1,
      "position": [
        320,
        300
      ],
      "continueOnFail": false
    },
    {
      "parameters": {
        "language": "python",
        "pythonCode": "trigger_item = _('Needs target resync?').first()\ntrigger = trigger_item.json if trigger_item and isinstance(trigger_item.json, dict) else {}\nresync_item = _input.first()\nresync = resync_item.json if resync_item and isinstance(resync_item.json, dict) else {}\nwf_d_payload = resync.get('wf_d_payload') if isinstance(resync.get('wf_d_payload'), list) else []\nproduct_id = str(trigger.get('product_id') or '')\nselected = None\nfor row in wf_d_payload:\n    if not isinstance(row, dict):\n        continue\n    if str(row.get('product_id') or '') == product_id:\n        selected = row\n        break\nif selected is None:\n    mapping = resync.get('target_mapping') if isinstance(resync.get('target_mapping'), dict) else {}\n    mapped = mapping.get(product_id) if isinstance(mapping, dict) else None\n    target_id = ''\n    if isinstance(mapped, dict):\n        target_id = str(mapped.get('target_id') or mapped.get('acunetix_target_id') or '').strip()\n    if not target_id:\n        raise Exception(f'WF_D_PT_AcunetixScan fallback error: resync completed but no target mapping for product_id={product_id}')\n    selected = {'product_id': trigger.get('product_id'), 'target_id': target_id, 'acunetix_target_id': target_id, 'selected_acu_node': trigger.get('selected_acu_node')}\n\nnode = selected.get('selected_acu_node') if isinstance(selected.get('selected_acu_node'), dict) else (trigger.get('selected_acu_node') if isinstance(trigger.get('selected_acu_node'), dict) else None)\nif not isinstance(node, dict):\n    raise Exception('WF_D_PT_AcunetixScan fallback error: selected_acu_node missing after WF_C_Targets_For_PT resync')\n\nreturn [{'json': {\n    **trigger,\n    'target_id': selected.get('target_id') or selected.get('acunetix_target_id') or trigger.get('target_id'),\n    'acunetix_target_id': selected.get('acunetix_target_id') or selected.get('target_id') or trigger.get('acunetix_target_id'),\n    'selected_acu_node': node,\n    'acunetix_node_name': node.get('name') or trigger.get('acunetix_node_name'),\n    'acunetix_endpoint': node.get('endpoint') or trigger.get('acunetix_endpoint'),\n    'acunetix_api_key': trigger.get('acunetix_api_key'),\n    'fallback_resync_completed': True,\n}}]"
      },
      "id": "d-merge-resync",
      "name": "Apply Resynced Target",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        540,
        300
      ]
    },
    {
      "parameters": {
        "keepOnlySet": true,
        "values": {
          "json": [
            {
              "name": "pt_id",
              "value": "={{$json.pt_id ?? $json.product_type_id}}"
            },
            {
              "name": "product_id",
              "value": "={{$json.product_id}}"
            },
            {
              "name": "product_name",
              "value": "={{$json.product_name}}"
            },
            {
              "name": "product_type_id",
              "value": "={{$json.product_type_id}}"
            },
            {
              "name": "domain",
              "value": "={{$json.domain}}"
            },
            {
              "name": "stage",
              "value": "={{$json.stage || 'acu'}}"
            },
            {
              "name": "target_id",
              "value": "={{$json.target_id ?? $json.acunetix_target_id}}"
            },
            {
              "name": "acunetix_target_id",
              "value": "={{$json.acunetix_target_id ?? $json.target_id}}"
            },
            {
              "name": "job_metadata",
              "value": "={{$json.job_metadata ?? {}}}"
            },
            {
              "name": "selected_acu_node",
              "value": "={{$json.selected_acu_node}}"
            },
            {
              "name": "acunetix_node_name",
              "value": "={{$json.acunetix_node_name}}"
            },
            {
              "name": "acunetix_endpoint",
              "value": "={{$json.acunetix_endpoint}}"
            },
            {
              "name": "acunetix_api_key",
              "value": "={{$json.acunetix_api_key}}"
            },
            {
              "name": "tag_signals",
              "value": "={{$json.tag_signals ?? {}}}"
            },
            {
              "name": "requires_target_resync",
              "value": "={{!!$json.requires_target_resync}}"
            },
            {
              "name": "resync_reason",
              "value": "={{$json.resync_reason}}"
            },
            {
              "name": "previous_selected_acu_node",
              "value": "={{$json.previous_selected_acu_node}}"
            }
          ]
        },
        "options": {}
      },
      "id": "set-dispatch-item",
      "name": "Map Dispatch Item",
      "type": "n8n-nodes-base.set",
      "typeVersion": 2,
      "position": [
        -30,
        200
      ]
    }
  ],
  "connections": {
    "Trigger": {
      "main": [
        [
          {
            "node": "Get PT Targets/Products",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get PT Targets/Products": {
      "main": [
        [
          {
            "node": "Get Active Acunetix Scans",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Active Acunetix Scans": {
      "main": [
        [
          {
            "node": "Build Dispatch Plan (Python)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Dispatch Plan (Python)": {
      "main": [
        [
          {
            "node": "Has capacity and products?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has capacity and products?": {
      "main": [
        [
          {
            "node": "Expand Dispatch Items (Items)",
            "type": "main",
            "index": 0
          }
        ],
        []
      ]
    },
    "Needs target resync?": {
      "main": [
        [
          {
            "node": "Run WF_C_Targets_For_PT",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Run WF_D_ProductScan",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Run WF_C_Targets_For_PT": {
      "main": [
        [
          {
            "node": "Apply Resynced Target",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Apply Resynced Target": {
      "main": [
        [
          {
            "node": "Run WF_D_ProductScan",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Expand Dispatch Items (Items)": {
      "main": [
        [
          {
            "node": "Map Dispatch Item",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Map Dispatch Item": {
      "main": [
        [
          {
            "node": "Needs target resync?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "tags": []
}
