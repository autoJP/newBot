{
  "name": "WF_C_Targets_For_PT",
  "nodes": [
    {
      "parameters": {},
      "name": "Trigger",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1,
      "position": [
        0,
        0
      ],
      "id": "8881a7ec-1878-4e10-94c8-6838f00aaacc"
    },
    {
      "parameters": {
        "values": {
          "string": [
            {
              "name": "product_type_id",
              "value": "={{ $json.product_type_id }}"
            },
            {
              "name": "acunetix_endpoint",
              "value": "={{ $json.acunetix_endpoint || $json.selected_acu_node?.endpoint || '' }}"
            },
            {
              "name": "acunetix_api_key",
              "value": "={{ $json.selected_acu_node?.api_key || $json.selected_acu_node?.token || '' }}"
            },
            {
              "name": "acunetix_token",
              "value": "={{ $json.selected_acu_node?.token || $json.selected_acu_node?.api_key || '' }}"
            },
            {
              "name": "acunetix_node_name",
              "value": "={{ $json.acunetix_node_name || $json.selected_acu_node?.name || '' }}"
            }
          ]
        },
        "options": {}
      },
      "name": "Set Parameters",
      "type": "n8n-nodes-base.set",
      "typeVersion": 1,
      "position": [
        208,
        0
      ],
      "id": "b60803c9-c7f8-4192-a02d-c71c6095580b"
    },
    {
      "parameters": {
        "command": "=DOJO_API_TOKEN=\"{{$env.DOJO_API_TOKEN}}\" \\\npython3 /opt/tools/process_nmap_ips_for_pt.py \\\n  --product-type-id {{$json[\"product_type_id\"].toString()}} \\\n  --xml-dir /tmp \\\n  --api-token \"$DOJO_API_TOKEN\""
      },
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        416,
        0
      ],
      "id": "3762ce5b-c66a-4a26-9b9f-83c039540cca",
      "name": "Execute Command"
    },
    {
      "parameters": {
        "command": "=python3 /opt/tools/acunetix_sync_pt.py \\\n  --dojo-base-url {{$env.DOJO_BASE_URL || 'http://localhost:8080/api/v2'}} \\\n  --dojo-api-token {{$env.DOJO_API_TOKEN}} \\\n  --product-type-id {{ $('Set Parameters').item.json.product_type_id }} \\\n  --acu-node-json '{{ JSON.stringify($(\"Validate Acunetix Node\").item.json.selected_acu_node) }}'\n "
      },
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        624,
        0
      ],
      "id": "2381b203-8544-4e50-a98f-0cfb818f3235",
      "name": "Sync Acunetix Group"
    },
    {
      "parameters": {
        "command": "=python3 /opt/tools/acunetix_set_group_scan_speed.py \\\n  --acu-node-json '{{ JSON.stringify($(\"Validate Acunetix Node\").item.json.selected_acu_node) }}' \\\n  --group-id {{ $json.group_id }} \\\n  --scan-speed sequential\n"
      },
      "type": "n8n-nodes-base.executeCommand",
      "typeVersion": 1,
      "position": [
        1040,
        0
      ],
      "id": "d7566881-9c82-4564-8538-2546bf40e85d",
      "name": "Execute Command1"
    },
    {
      "parameters": {
        "language": "python",
        "pythonCode": "import errno\nimport fcntl\nimport json\nimport os\nimport tempfile\nimport time\n\nitem = items[0]\ncontext = item.get(\"json\", {})\nstdout = context.get(\"stdout\", \"\")\n\ntry:\n    parsed = json.loads(stdout)\nexcept Exception as e:\n    raise Exception(f\"Не удалось распарсить stdout как JSON:\n{stdout}\nОшибка: {e}\")\n\npt_id = context.get('pt_id', context.get('product_type_id'))\npt_id_str = str(pt_id) if pt_id is not None else ''\ndef normalize_selected_node(raw):\n    if not isinstance(raw, dict):\n        return None\n    endpoint = str(raw.get('endpoint') or '').strip().rstrip('/')\n    token = str(raw.get('api_key') or raw.get('token') or '').strip()\n    if not endpoint or not token:\n        return None\n    return {\n        'endpoint': endpoint,\n        'api_key': token,\n        'token': token,\n        'name': str(raw.get('name') or 'acu-selected').strip() or 'acu-selected',\n        'weight': max(1, int(raw.get('weight', 1) or 1)),\n    }\n\n\ndef nodes_equal(lhs, rhs):\n    if not isinstance(lhs, dict) or not isinstance(rhs, dict):\n        return False\n    return str(lhs.get('endpoint') or '').strip().rstrip('/') == str(rhs.get('endpoint') or '').strip().rstrip('/') and str(lhs.get('name') or '').strip() == str(rhs.get('name') or '').strip()\n\nselected_node = normalize_selected_node(context.get('selected_acu_node'))\ntarget_mapping = parsed.get(\"target_mapping\", {})\n\ncreation_node = parsed.get('debug', {}).get('acu_base_url')\nselected_endpoint = (selected_node or {}).get('endpoint')\nif selected_endpoint and creation_node:\n    lhs = str(selected_endpoint).strip().rstrip('/')\n    rhs = str(creation_node).strip().rstrip('/')\n    if lhs != rhs:\n        raise Exception(\n            f\"Target creation node mismatch: selected endpoint '{lhs}' != actual sync endpoint '{rhs}'.\"\n        )\n\nnormalized_mapping = {}\nwf_d_payload = []\nif isinstance(target_mapping, dict):\n    for dojo_product_id, acunetix_target_id in target_mapping.items():\n        dojo_product_id = str(dojo_product_id or '').strip()\n        acunetix_target_id = str(acunetix_target_id or '').strip()\n        if not dojo_product_id or not acunetix_target_id:\n            continue\n        row = {\n            'dojo_product_id': dojo_product_id,\n            'acunetix_target_id': acunetix_target_id,\n            'target_id': acunetix_target_id,\n            'pt_id': pt_id,\n        }\n        normalized_mapping[dojo_product_id] = row\n        wf_d_payload.append({\n            'pt_id': pt_id,\n            'product_id': dojo_product_id,\n            'target_id': acunetix_target_id,\n            'acunetix_target_id': acunetix_target_id,\n            'selected_acu_node': selected_node,\n        })\n\n\ndef read_modify_write_json(file_path, updater, label):\n    lock_retry_max_attempts = max(1, int(os.environ.get('ACUNETIX_LOCK_RETRY_MAX', '20') or '20'))\n    lock_retry_sleep_ms = max(1, int(os.environ.get('ACUNETIX_LOCK_RETRY_SLEEP_MS', '100') or '100'))\n\n    lock_file = f\"{file_path}.lock\"\n    lock_dir = os.path.dirname(lock_file)\n    if lock_dir:\n        os.makedirs(lock_dir, exist_ok=True)\n\n    write_started = time.monotonic()\n    lock_wait_started = write_started\n    retries = 0\n    lock_acquired = False\n\n    with open(lock_file, 'a+', encoding='utf-8') as lock_handle:\n        for attempt in range(1, lock_retry_max_attempts + 1):\n            try:\n                fcntl.flock(lock_handle.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)\n                lock_acquired = True\n                break\n            except OSError as lock_error:\n                if lock_error.errno not in (errno.EACCES, errno.EAGAIN):\n                    raise\n                retries += 1\n                if attempt >= lock_retry_max_attempts:\n                    raise TimeoutError(\n                        f\"{label} lock busy after {lock_retry_max_attempts} attempts and {lock_retry_sleep_ms}ms interval\"\n                    )\n                time.sleep((lock_retry_sleep_ms * (2 ** (attempt - 1))) / 1000.0)\n\n        lock_wait_ms = int((time.monotonic() - lock_wait_started) * 1000)\n\n        existing_items = {}\n        if os.path.exists(file_path):\n            with open(file_path, 'r', encoding='utf-8') as f:\n                loaded = json.load(f)\n                if isinstance(loaded, dict) and isinstance(loaded.get('items'), dict):\n                    existing_items = loaded.get('items')\n\n        updated_items = updater(dict(existing_items))\n        payload = {'items': updated_items}\n\n        file_dir = os.path.dirname(file_path) or '.'\n        os.makedirs(file_dir, exist_ok=True)\n\n        temp_path = None\n        try:\n            fd, temp_path = tempfile.mkstemp(prefix=f'.{label}_tmp_', suffix='.json', dir=file_dir)\n            with os.fdopen(fd, 'w', encoding='utf-8') as temp_handle:\n                json.dump(payload, temp_handle, ensure_ascii=False, indent=2)\n                temp_handle.flush()\n                os.fsync(temp_handle.fileno())\n            os.replace(temp_path, file_path)\n            temp_path = None\n        finally:\n            if temp_path and os.path.exists(temp_path):\n                os.unlink(temp_path)\n\n        fcntl.flock(lock_handle.fileno(), fcntl.LOCK_UN)\n\n    write_duration_ms = int((time.monotonic() - write_started) * 1000)\n\n    return payload, {\n        'lock_wait_ms': lock_wait_ms,\n        'write_retries': retries,\n        'lock_acquired': lock_acquired,\n        'write_duration_ms': write_duration_ms,\n    }\n\n\nmapping_file = (os.environ.get('ACUNETIX_TARGET_MAPPING_FILE') or '/tmp/acunetix_dojo_target_mapping.json').strip()\npt_node_mapping_file = (os.environ.get('ACUNETIX_PT_NODE_MAPPING_FILE') or '/tmp/acunetix_pt_node_mapping.json').strip()\n\nmapping_merge_report = {\n    'before_merge_count': 0,\n    'after_merge_count': 0,\n    'removed_for_current_pt_count': 0,\n    'removed_by_pt_id_count': 0,\n    'removed_by_product_type_id_count': 0,\n    'final_after_upsert_count': 0,\n    'upserted_current_pt_count': len(normalized_mapping),\n    'pt_id': pt_id,\n}\n\nmapping_output = {'items': {}}\npt_node_mapping_output = {'items': {}}\npt_node_reconcile = {'status': 'noop', 'event': None}\nmapping_lock_wait_ms = 0\nmapping_lock_acquired = False\nmapping_write_retries = 0\nmapping_write_duration_ms = 0\npt_node_lock_wait_ms = 0\npt_node_lock_acquired = False\npt_node_write_retries = 0\npt_node_write_duration_ms = 0\n\nif mapping_file:\n    try:\n        def update_mapping(merged_items):\n            mapping_merge_report['before_merge_count'] = len(merged_items)\n\n            if pt_id_str:\n                to_remove = []\n                removed_by_pt_id_count = 0\n                removed_by_product_type_id_count = 0\n\n                for product_id, row in merged_items.items():\n                    if not isinstance(row, dict):\n                        continue\n\n                    row_pt_id = str(row.get('pt_id')).strip() if row.get('pt_id') is not None else ''\n                    row_product_type_id = str(row.get('product_type_id')).strip() if row.get('product_type_id') is not None else ''\n\n                    if row_pt_id and row_pt_id == pt_id_str:\n                        to_remove.append(product_id)\n                        removed_by_pt_id_count += 1\n                    elif row_product_type_id and row_product_type_id == pt_id_str:\n                        to_remove.append(product_id)\n                        removed_by_product_type_id_count += 1\n\n                for product_id in to_remove:\n                    merged_items.pop(product_id, None)\n\n                mapping_merge_report['removed_by_pt_id_count'] = removed_by_pt_id_count\n                mapping_merge_report['removed_by_product_type_id_count'] = removed_by_product_type_id_count\n                mapping_merge_report['removed_for_current_pt_count'] = removed_by_pt_id_count + removed_by_product_type_id_count\n\n            for product_id, row in normalized_mapping.items():\n                merged_items[product_id] = row\n\n            mapping_merge_report['after_merge_count'] = len(merged_items)\n            mapping_merge_report['final_after_upsert_count'] = len(merged_items)\n            return merged_items\n\n        mapping_output, mapping_stats = read_modify_write_json(\n            mapping_file,\n            update_mapping,\n            'mapping'\n        )\n        mapping_lock_wait_ms = mapping_stats.get('lock_wait_ms', 0)\n        mapping_lock_acquired = bool(mapping_stats.get('lock_acquired'))\n        mapping_write_retries = mapping_stats.get('write_retries', 0)\n        mapping_write_duration_ms = mapping_stats.get('write_duration_ms', 0)\n    except Exception as e:\n        raise Exception(f\"Не удалось сохранить mapping в {mapping_file}: {e}\")\n\nif pt_node_mapping_file:\n    try:\n        def update_pt_node(items_by_pt):\n            if pt_id is not None and isinstance(selected_node, dict) and selected_node.get('endpoint') and (selected_node.get('api_key') or selected_node.get('token')):\n                cache_before = normalize_selected_node(items_by_pt.get(str(pt_id)))\n                if cache_before and not nodes_equal(cache_before, selected_node):\n                    pt_node_reconcile['status'] = 'reconciled'\n                    pt_node_reconcile['event'] = {\n                        'stage': 'wf_c_targets_for_pt',\n                        'pt_id': pt_id,\n                        'message': 'PT→Acunetix node cache mismatch detected; secondary cache synchronized from primary runtime node.',\n                        'primary': {'endpoint': selected_node.get('endpoint'), 'name': selected_node.get('name')},\n                        'secondary_before': {'endpoint': cache_before.get('endpoint'), 'name': cache_before.get('name')},\n                    }\n                items_by_pt[str(pt_id)] = {\n                    'endpoint': selected_node.get('endpoint'),\n                    'api_key': selected_node.get('api_key') or selected_node.get('token'),\n                    'token': selected_node.get('token') or selected_node.get('api_key'),\n                    'name': selected_node.get('name') or 'acu-selected',\n                    'weight': selected_node.get('weight', 1),\n                    'saved_at': parsed.get('debug', {}).get('synced_at') or None,\n                    'source': 'primary_pt_state',\n                }\n            return items_by_pt\n\n        pt_node_mapping_output, pt_node_stats = read_modify_write_json(\n            pt_node_mapping_file,\n            update_pt_node,\n            'pt_node_mapping'\n        )\n        pt_node_lock_wait_ms = pt_node_stats.get('lock_wait_ms', 0)\n        pt_node_lock_acquired = bool(pt_node_stats.get('lock_acquired'))\n        pt_node_write_retries = pt_node_stats.get('write_retries', 0)\n        pt_node_write_duration_ms = pt_node_stats.get('write_duration_ms', 0)\n    except Exception as e:\n        raise Exception(f\"Не удалось сохранить PT node mapping в {pt_node_mapping_file}: {e}\")\n\nlock_wait_ms = mapping_lock_wait_ms + pt_node_lock_wait_ms\nwrite_retries = mapping_write_retries + pt_node_write_retries\nwrite_duration_ms = mapping_write_duration_ms + pt_node_write_duration_ms\n\nreturn [{\n    \"json\": {\n        \"pt_id\": pt_id,\n        \"selected_acu_node\": selected_node,\n        \"group_id\": parsed.get(\"group_id\"),\n        \"target_mapping\": normalized_mapping,\n        \"dojo_product_to_acunetix_target_mapping\": normalized_mapping,\n        \"mapping_output\": mapping_output,\n        \"mapping_merge_report\": mapping_merge_report,\n        \"mapping_lock_wait_ms\": mapping_lock_wait_ms,\n        \"mapping_lock_acquired\": mapping_lock_acquired,\n        \"mapping_write_retries\": mapping_write_retries,\n        \"mapping_write_duration_ms\": mapping_write_duration_ms,\n        \"pt_node_lock_wait_ms\": pt_node_lock_wait_ms,\n        \"pt_node_lock_acquired\": pt_node_lock_acquired,\n        \"pt_node_write_retries\": pt_node_write_retries,\n        \"pt_node_write_duration_ms\": pt_node_write_duration_ms,\n        \"lock_wait_ms\": lock_wait_ms,\n        \"write_retries\": write_retries,\n        \"write_duration_ms\": write_duration_ms,\n        \"target_mapping_file\": mapping_file,\n        \"pt_node_mapping_file\": pt_node_mapping_file,\n        \"pt_node_mapping_output\": pt_node_mapping_output,\n        \"pt_node_reconcile\": pt_node_reconcile,\n        \"creation_node_check\": {\n            \"selected_endpoint\": selected_endpoint,\n            \"sync_endpoint\": creation_node,\n            \"match\": (str(selected_endpoint).strip().rstrip('/') == str(creation_node).strip().rstrip('/')) if selected_endpoint and creation_node else None,\n        },\n        \"wf_d_payload\": wf_d_payload,\n        \"sync_summary\": {\"group_id\": parsed.get(\"group_id\"), \"mapped_targets\": len(normalized_mapping), \"has_debug\": isinstance(parsed.get(\"debug\"), dict)}\n    }\n}]"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        832,
        0
      ],
      "id": "4c48ade9-718e-405b-89c1-1beab80ed6e0",
      "name": "Code in Python (Beta)"
    },
    {
      "parameters": {
        "language": "python",
        "pythonCode": "item = $json\nraw = item.get('product_type_id')\n\ntry:\n    product_type_id = int(raw)\nexcept Exception:\n    raise Exception(f'product_type_id is missing or invalid: {raw}')\n\nif product_type_id <= 0:\n    raise Exception(f'product_type_id must be > 0, got: {raw}')\n\nreturn [{\n    'json': {\n        **item,\n        'product_type_id': product_type_id\n    }\n}]"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        320,
        0
      ],
      "id": "c-validate-product-type-id",
      "name": "Validate Product Type ID"
    },
    {
      "parameters": {
        "language": "python",
        "pythonCode": "import json\nimport os\n\n\ndef parse_positive_int(value, default):\n    try:\n        parsed = int(value)\n        if parsed > 0:\n            return parsed\n    except Exception:\n        pass\n    return default\n\n\ndef normalize_selected_node(raw):\n    if not isinstance(raw, dict):\n        return None\n    endpoint = str(raw.get('endpoint') or '').strip().rstrip('/')\n    token = str(raw.get('api_key') or raw.get('token') or '').strip()\n    if not endpoint:\n        return None\n    if not token:\n        return {\n            'endpoint': endpoint,\n            'name': str(raw.get('name') or 'acu-selected').strip() or 'acu-selected',\n            'weight': parse_positive_int(raw.get('weight', 1), 1),\n        }\n    return {\n        'endpoint': endpoint,\n        'api_key': token,\n        'token': token,\n        'name': str(raw.get('name') or 'acu-selected').strip() or 'acu-selected',\n        'weight': parse_positive_int(raw.get('weight', 1), 1),\n    }\n\n\nitem = $json\npt_id = item.get('pt_id', item.get('product_type_id'))\nincoming_selected_node = normalize_selected_node(item.get('selected_acu_node')) or {}\n\nendpoint = str(item.get('acunetix_endpoint') or incoming_selected_node.get('endpoint') or '').strip().rstrip('/')\nnode_name = (item.get('acunetix_node_name') or incoming_selected_node.get('name') or 'acu-selected').strip() or 'acu-selected'\n\nif not endpoint:\n    raise Exception(f'WF_C_Targets_For_PT stage config error (pt_id={pt_id}): acunetix_endpoint is required. Pass selected node endpoint from orchestrator payload.')\n\nruntime_api_key = str(incoming_selected_node.get('api_key') or incoming_selected_node.get('token') or '').strip()\n\nif not runtime_api_key:\n    raw_nodes = (os.environ.get('ACUNETIX_INSTANCES_JSON') or '').strip()\n    if raw_nodes:\n        try:\n            parsed_nodes = json.loads(raw_nodes)\n            if isinstance(parsed_nodes, list):\n                normalized_endpoint = endpoint.rstrip('/')\n                for candidate in parsed_nodes:\n                    normalized_candidate = normalize_selected_node(candidate)\n                    if not normalized_candidate:\n                        continue\n                    candidate_endpoint = str(normalized_candidate.get('endpoint') or '').strip().rstrip('/')\n                    candidate_name = str(normalized_candidate.get('name') or '').strip()\n                    if candidate_endpoint == normalized_endpoint or (candidate_name and candidate_name == node_name):\n                        runtime_api_key = str(normalized_candidate.get('api_key') or normalized_candidate.get('token') or '').strip()\n                        if runtime_api_key:\n                            if not node_name and candidate_name:\n                                node_name = candidate_name\n                            break\n        except Exception:\n            runtime_api_key = runtime_api_key\n\nif not runtime_api_key:\n    raise Exception(f'WF_C_Targets_For_PT stage config error (pt_id={pt_id}): Acunetix API key must come from runtime selected_acu_node or ACUNETIX_INSTANCES_JSON.')\n\nselected_node = normalize_selected_node({\n    'endpoint': endpoint,\n    'api_key': runtime_api_key,\n    'token': runtime_api_key,\n    'name': node_name,\n    'weight': incoming_selected_node.get('weight', 1),\n})\n\nreturn [{\n    'json': {\n        **item,\n        'pt_id': item.get('pt_id', item.get('product_type_id')),\n        'selected_acu_node': selected_node,\n        'acunetix_endpoint': endpoint,\n        'acunetix_api_key': runtime_api_key,\n        'acunetix_token': runtime_api_key,\n        'acunetix_node_name': node_name,\n        'acu_node_source': 'runtime_config',\n    }\n}]"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        496,
        0
      ],
      "id": "c-validate-acunetix-node",
      "name": "Validate Acunetix Node"
    }
  ],
  "pinData": {},
  "connections": {
    "Trigger": {
      "main": [
        [
          {
            "node": "Set Parameters",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Set Parameters": {
      "main": [
        [
          {
            "node": "Validate Product Type ID",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Execute Command": {
      "main": [
        [
          {
            "node": "Sync Acunetix Group",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Sync Acunetix Group": {
      "main": [
        [
          {
            "node": "Code in Python (Beta)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code in Python (Beta)": {
      "main": [
        [
          {
            "node": "Execute Command1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validate Product Type ID": {
      "main": [
        [
          {
            "node": "Validate Acunetix Node",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validate Acunetix Node": {
      "main": [
        [
          {
            "node": "Execute Command",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "f219f7ce-7867-484a-8806-8e183d70eba5",
  "meta": {
    "instanceId": "d06b9c37a455942c350bdf64d5764dfb5548ea5097bfb316251734323f35ea3f"
  },
  "id": "OsOBICmnEtSDo8Sm",
  "tags": []
}
