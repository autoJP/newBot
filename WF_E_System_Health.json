{
  "name": "WF_E_System_Health",
  "nodes": [
    {
      "parameters": {},
      "id": "h-trigger",
      "name": "Trigger",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1,
      "position": [
        -980,
        180
      ]
    },
    {
      "parameters": {
        "authentication": "headerAuth",
        "url": "={{ ($env.DOJO_BASE_URL || 'http://localhost:8080/api/v2').replace(/\\/+$/,'') + '/system_settings/' }}",
        "options": {
          "ignoreHttpStatusErrors": true,
          "fullResponse": true
        }
      },
      "id": "h-dojo",
      "name": "Check Dojo",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        -760,
        180
      ],
      "credentials": {
        "httpHeaderAuth": {
          "id": "mGl4PbJkKfeJbTg8",
          "name": "Header Auth account"
        }
      }
    },
    {
      "parameters": {
        "language": "python",
        "pythonCode": "import os, json, urllib.request\nraw = (os.environ.get('ACUNETIX_INSTANCES_JSON') or '').strip()\nnodes = []\nlegacy_token_used = False\nsource = 'instances_json' if raw else 'env_default'\nconfig_error = None\nif raw:\n    try:\n        arr = json.loads(raw)\n        if isinstance(arr, list):\n            for i in arr:\n                if not isinstance(i, dict):\n                    continue\n                endpoint = str(i.get('endpoint') or '').strip()\n                token = str(i.get('api_key') or i.get('token') or '').strip()\n                if endpoint and token:\n                    nodes.append({**i, 'endpoint': endpoint, 'api_key': token, 'token': token})\n    except Exception:\n        nodes = []\nif raw and not nodes:\n    config_error = 'WF_E_System_Health stage config error: ACUNETIX_INSTANCES_JSON has no valid nodes with endpoint+api_key/token.'\nif not nodes:\n    primary_token = (os.environ.get('ACUNETIX_API_KEY') or '').strip()\n    legacy_token = (os.environ.get('ACU_API_TOKEN') or '').strip()\n    token = primary_token or legacy_token\n    legacy_token_used = bool((not primary_token) and legacy_token)\n    nodes = [{'name':'acu-default','endpoint': os.environ.get('ACUNETIX_BASE_URL','https://localhost:3443'),'api_key': token, 'token': token}]\n    if not token and not config_error:\n        config_error = 'WF_E_System_Health stage config error: ACUNETIX_API_KEY is empty (temporary fallback: ACU_API_TOKEN).'\n\nreports = []\nhealthy = 0\nfor idx, n in enumerate(nodes):\n    endpoint = str(n.get('endpoint') or '').rstrip('/')\n    token = str(n.get('api_key') or n.get('token') or '').strip()\n    name = n.get('name') or f'acu-{idx+1}'\n    status_code = None\n    ok = False\n    error = None\n    if not endpoint:\n        error = 'missing_endpoint'\n    elif not token:\n        error = 'missing_api_key'\n    else:\n        try:\n            req=urllib.request.Request(endpoint+'/api/v1/me')\n            req.add_header('X-Auth', token)\n            with urllib.request.urlopen(req, timeout=6) as resp:\n                status_code = getattr(resp,'status',200)\n                ok = 200 <= status_code <= 299\n            if not ok:\n                error = f'unexpected_status:{status_code}'\n        except Exception as e:\n            error = str(e)\n            ok = False\n    reports.append({'name':name,'endpoint':endpoint,'statusCode':status_code,'ok':ok,'error':error})\n    if ok:\n        healthy += 1\n\nreturn [{'json': {'statusCode': 200 if healthy>0 and not config_error else 503, 'healthy_nodes': healthy, 'total_nodes': len(reports), 'nodes': reports, 'token_diagnostics': {'source': source, 'legacy_token_used': legacy_token_used}, 'config_error': config_error}}]"
      },
      "id": "h-acu",
      "name": "Check Acunetix Node",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -540,
        180
      ]
    },
    {
      "parameters": {
        "language": "python",
        "pythonCode": "from datetime import datetime, timezone\nimport json\nimport os\nimport re\nimport urllib.request\n\nnow = datetime.now(timezone.utc).isoformat()\nBLOCK_START = 'PT_STATE_JSON_START'\nBLOCK_END = 'PT_STATE_JSON_END'\nVALID_STATES = {'new','subdomains_running','subdomains_done','nmap_running','nmap_done','targets_ready','acu_running','done','error'}\nREQUIRED_STATE_KEYS = {'state', 'version', 'counters', 'last_update', 'retry_count', 'last_stage'}\n\n\ndef status_in_ranges(status_code, ranges):\n    if status_code is None:\n        return False\n    for low, high in ranges:\n        if low <= status_code <= high:\n            return True\n    return False\n\n\ndef extract_state_block(description):\n    if not isinstance(description, str):\n        return None, ['description_not_string']\n\n    start_count = description.count(BLOCK_START)\n    end_count = description.count(BLOCK_END)\n    if start_count != 1 or end_count != 1:\n        return None, [f'invalid_marker_count:start={start_count},end={end_count}']\n\n    m = re.search(rf\"{BLOCK_START}\\n(.*?)\\n{BLOCK_END}\", description, re.DOTALL)\n    if not m:\n        return None, ['state_block_markers_malformed']\n\n    return m.group(1).strip(), []\n\n\ndef parse_state_with_integrity(description):\n    payload_raw, errors = extract_state_block(description)\n    if errors:\n        return {}, errors\n\n    try:\n        payload = json.loads(payload_raw)\n    except Exception as e:\n        return {}, [f'invalid_json:{e}']\n\n    if not isinstance(payload, dict):\n        return {}, ['state_payload_not_object']\n\n    key_errors = []\n    missing = sorted(REQUIRED_STATE_KEYS - set(payload.keys()))\n    if missing:\n        key_errors.append('missing_required_keys:' + ','.join(missing))\n\n    state = str(payload.get('state') or '')\n    if state not in VALID_STATES:\n        key_errors.append(f'invalid_state:{state}')\n\n    return payload, key_errors\n\n\ndef to_results(node_name):\n    data = $node[node_name].json if $node[node_name].json else {}\n    if isinstance(data, dict):\n        return data\n    return {}\n\n\ndef fetch_next_pages(initial_next):\n    token = (os.environ.get('DOJO_API_TOKEN') or '').strip()\n    if not initial_next or not token:\n        return []\n    out = []\n    visited = set()\n    current = str(initial_next)\n    while current and current not in visited:\n        visited.add(current)\n        req = urllib.request.Request(current)\n        req.add_header('Authorization', f'Token {token}')\n        req.add_header('Accept', 'application/json')\n        with urllib.request.urlopen(req, timeout=20) as resp:\n            payload = json.loads((resp.read() or b'{}').decode('utf-8'))\n        out.extend(payload.get('results') or [])\n        current = payload.get('next')\n    return out\n\nservices = [\n    ('dojo', 'Check Dojo', [(200, 299)]),\n    ('acunetix', 'Check Acunetix Node', [(200, 299)]),\n    ('mapping_backend', 'Check Mapping Backend', [(200, 299)]),\n]\n\nreport = {}\ncritical = []\nlog_events = []\nnode_errors = []\n\nfor service_name, node_name, expected_ranges in services:\n    node_data = to_results(node_name)\n    status_code = node_data.get('statusCode')\n    ok = status_in_ranges(status_code, expected_ranges)\n    error_message = None\n    if status_code is None:\n        error_message = 'no_status_code_returned'\n    elif not ok:\n        error_message = f'unexpected_status_code:{status_code}'\n    report[service_name] = {\n        'ok': ok,\n        'status_code': status_code,\n        'error_message': error_message,\n        'checked_at': now,\n    }\n    log_events.append({\n        'pt_id': None,\n        'stage': f'health_{service_name}',\n        'job_id': service_name,\n        'server': service_name,\n        'status': 'ok' if ok else 'error',\n        'duration': None,\n    })\n    if not ok:\n        critical.append(f'{service_name}_unavailable')\n        node_errors.append({'node': service_name, 'error': error_message})\n\nif report.get('mapping_backend', {}).get('ok'):\n    mapping_data = to_results('Check Mapping Backend')\n    bad_rows = int((mapping_data.get('stats') or {}).get('rows_without_pt_or_product') or 0)\n    if bad_rows > 0:\n        critical.append('mapping_backend_integrity')\n        node_errors.append({'node': 'mapping_backend', 'error': f'rows_without_pt_or_product:{bad_rows}'})\n\nmapping_data = to_results('Check Mapping Backend')\nfor warn in mapping_data.get('warnings', []) or []:\n    log_events.append({\n        'pt_id': None,\n        'stage': 'mapping_backend_health',\n        'job_id': 'mapping_backend',\n        'server': mapping_data.get('path') or 'mapping_backend',\n        'status': 'warning',\n        'duration': None,\n    })\n    node_errors.append({'node': 'mapping_backend', 'error': str(warn)})\n\nacu_data = to_results('Check Acunetix Node')\nfor n in acu_data.get('nodes', []) or []:\n    if not n.get('ok'):\n        node_errors.append({'node': n.get('name'), 'error': f\"statusCode:{n.get('statusCode')}\"})\n    log_events.append({\n        'pt_id': None,\n        'stage': 'acu_node_health',\n        'job_id': n.get('name'),\n        'server': n.get('endpoint') or n.get('name'),\n        'status': 'ok' if n.get('ok') else 'error',\n        'duration': None,\n    })\n\npt_payload = to_results('Get PT States')\nproduct_types = list(pt_payload.get('results') or [])\nproduct_types.extend(fetch_next_pages(pt_payload.get('next')))\npt_window = int(os.environ.get('PT_HEALTH_WINDOW_SIZE', '300') or 300)\nproduct_types = product_types[:max(1, pt_window)]\n\nstate_counts = {state: 0 for state in VALID_STATES}\nqueues = {'subdomains': 0, 'nmap': 0, 'acu': 0}\nactive_slots = {'subdomains': 0, 'nmap': 0, 'acu': 0}\npt_errors = []\nstate_integrity_issues = []\n\nfor pt in product_types:\n    pt_id = pt.get('id')\n    state_obj, integrity_errors = parse_state_with_integrity(pt.get('description', ''))\n\n    if integrity_errors:\n        state_integrity_issues.append({'pt_id': pt_id, 'errors': integrity_errors})\n        critical.append(f'pt_state_integrity:{pt_id}')\n        node_errors.append({'node': f'pt:{pt_id}', 'error': ';'.join(integrity_errors)})\n        log_events.append({\n            'pt_id': pt_id,\n            'stage': 'pt_state_integrity',\n            'job_id': f'pt:{pt_id}',\n            'server': 'dojo:pt_state',\n            'status': 'error',\n            'duration': None,\n        })\n\n    state = str(state_obj.get('state') or 'new')\n    if state not in VALID_STATES:\n        state = 'new'\n    state_counts[state] = state_counts.get(state, 0) + 1\n\n    if state in {'new', 'error'}:\n        queues['subdomains'] += 1\n    if state in {'subdomains_done', 'nmap_running'}:\n        queues['nmap'] += 1\n    if state in {'targets_ready', 'acu_running'}:\n        queues['acu'] += 1\n\n    if state == 'subdomains_running':\n        active_slots['subdomains'] += 1\n    if state == 'nmap_running':\n        active_slots['nmap'] += 1\n    if state == 'acu_running':\n        active_slots['acu'] += 1\n\n    if state == 'error':\n        err = str(state_obj.get('last_error') or 'unknown_error')\n        stage = str(state_obj.get('last_stage') or 'unknown_stage')\n        pt_errors.append({'pt_id': pt_id, 'stage': stage, 'error': err})\n        log_events.append({\n            'pt_id': pt_id,\n            'stage': stage,\n            'job_id': f'pt:{pt_id}',\n            'server': 'dojo:pt_state',\n            'status': 'error',\n            'duration': None,\n        })\n\nmax_events = int(os.environ.get('HEALTH_MAX_LOG_EVENTS', '500') or 500)\nif max_events > 0:\n    log_events = log_events[:max_events]\n\ncritical = sorted(set(critical))\n\nstate_patch_failed = 0\nfor err in pt_errors:\n    stage_val = str(err.get('stage') or '').lower()\n    msg_val = str(err.get('error') or '').lower()\n    if stage_val.startswith('state_patch') or 'state patch' in msg_val or 'pt-state patch' in msg_val:\n        state_patch_failed += 1\n\nreturn [{\n  'json': {\n    **report,\n    'critical': critical,\n    'has_critical': len(critical) > 0,\n    'checked_at': now,\n    'pt_window_size': pt_window,\n    'pt_state_counts': state_counts,\n    'queue_status': queues,\n    'active_slots': active_slots,\n    'pt_errors': pt_errors,\n    'pt_state_integrity': {\n        'issues_count': len(state_integrity_issues),\n        'issues': state_integrity_issues,\n        'required_keys': sorted(list(REQUIRED_STATE_KEYS)),\n        'valid_states': sorted(list(VALID_STATES)),\n    },\n    'node_errors': node_errors,\n    'state_patch_failed': state_patch_failed,\n    'log_events': log_events,\n  }\n}]"
      },
      "id": "h-report",
      "name": "Build Unified Report (Python)",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -100,
        180
      ]
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.has_critical }}"
            }
          ]
        }
      },
      "id": "h-if",
      "name": "Critical issues?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 1,
      "position": [
        120,
        180
      ]
    },
    {
      "parameters": {
        "url": "={{ $env.HEALTH_ALERT_WEBHOOK || '' }}",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json }}",
        "options": {}
      },
      "id": "h-alert",
      "name": "Send Critical Alert",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        340,
        100
      ]
    },
    {
      "parameters": {
        "authentication": "headerAuth",
        "url": "={{ ($env.DOJO_BASE_URL || 'http://localhost:8080/api/v2').replace(/\\/+$/,'') + '/product_types/?limit=200&offset=0' }}",
        "options": {
          "ignoreHttpStatusErrors": true,
          "fullResponse": true
        }
      },
      "id": "h-pt-states",
      "name": "Get PT States",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [
        -760,
        340
      ],
      "credentials": {
        "httpHeaderAuth": {
          "id": "mGl4PbJkKfeJbTg8",
          "name": "Header Auth account"
        }
      }
    },
    {
      "parameters": {
        "language": "python",
        "pythonCode": "import os\nimport sqlite3\n\nprimary_path = (os.environ.get('ACUNETIX_MAPPING_DB') or '/data/n8n/acunetix_mapping_store.sqlite3').strip()\ndebug_path = (os.environ.get('ACUNETIX_MAPPING_DEBUG_CACHE') or '/tmp/acunetix_mapping_store.debug.sqlite3').strip()\nallow_debug = str(os.environ.get('ACUNETIX_MAPPING_ALLOW_DEBUG_FALLBACK') or '').strip().lower() in {'1','true','yes','on'}\n\npath = primary_path\nrole = 'primary'\nif (not path or path.startswith('/tmp/')) and allow_debug and debug_path:\n    path = debug_path\n    role = 'debug-cache'\n\nstatus_code = 200\nok = True\nerrors = []\nwarnings = []\nstats = {'total_rows': 0, 'rows_without_target': 0, 'rows_without_pt_or_product': 0, 'distinct_pt': 0}\n\nif not path:\n    ok = False\n    status_code = 503\n    errors.append('mapping_db_path_empty')\nelse:\n    if path.startswith('/tmp/'):\n        warnings.append('mapping_path_is_tmp')\n    try:\n        conn = sqlite3.connect(path, timeout=6)\n        with conn:\n            conn.execute('CREATE TABLE IF NOT EXISTS acunetix_mapping (pt_id TEXT NOT NULL, product_id TEXT NOT NULL, selected_acu_node TEXT, target_id TEXT, updated_at TEXT NOT NULL, PRIMARY KEY (pt_id, product_id))')\n            stats['total_rows'] = int(conn.execute('SELECT COUNT(1) FROM acunetix_mapping').fetchone()[0])\n            stats['rows_without_target'] = int(conn.execute(\"SELECT COUNT(1) FROM acunetix_mapping WHERE target_id IS NULL OR TRIM(target_id) = ''\").fetchone()[0])\n            stats['rows_without_pt_or_product'] = int(conn.execute(\"SELECT COUNT(1) FROM acunetix_mapping WHERE pt_id IS NULL OR TRIM(pt_id) = '' OR product_id IS NULL OR TRIM(product_id) = ''\").fetchone()[0])\n            stats['distinct_pt'] = int(conn.execute('SELECT COUNT(DISTINCT pt_id) FROM acunetix_mapping').fetchone()[0])\n    except Exception as e:\n        ok = False\n        status_code = 503\n        errors.append(f'sqlite_unavailable:{e}')\n\nif stats['rows_without_pt_or_product'] > 0:\n    ok = False\n    status_code = 503\n    errors.append(f\"mapping_integrity_rows_without_pt_or_product:{stats['rows_without_pt_or_product']}\")\nif stats['rows_without_target'] > 0:\n    warnings.append(f\"mapping_rows_without_target:{stats['rows_without_target']}\")\n\nreturn [{'json': {'statusCode': status_code, 'ok': ok, 'backend': 'sqlite', 'path': path, 'role': role, 'stats': stats, 'warnings': warnings, 'errors': errors}}]"
      },
      "id": "h-mapping-backend",
      "name": "Check Mapping Backend",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -210,
        20
      ]
    }
  ],
  "connections": {
    "Trigger": {
      "main": [
        [
          {
            "node": "Check Dojo",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Dojo": {
      "main": [
        [
          {
            "node": "Get PT States",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Acunetix Node": {
      "main": [
        [
          {
            "node": "Check Mapping Backend",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Unified Report (Python)": {
      "main": [
        [
          {
            "node": "Critical issues?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Critical issues?": {
      "main": [
        [
          {
            "node": "Send Critical Alert",
            "type": "main",
            "index": 0
          }
        ],
        []
      ]
    },
    "Get PT States": {
      "main": [
        [
          {
            "node": "Check Acunetix Node",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Mapping Backend": {
      "main": [
        [
          {
            "node": "Build Unified Report (Python)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "tags": []
}
